{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Preprocessing Params\n",
    "\n",
    "This notebook should be used to set up preprocessing params.\n",
    "Cells marked with <font color='red'>SET PARAMETERS</font> contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/brieflow_main_env/lib/python3.11/site-packages/microfilm/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, DistributionNotFound\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "from microfilm.microplot import Microimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from lib.shared.configuration_utils import (\n",
    "    CONFIG_FILE_HEADER,\n",
    "    create_samples_df,\n",
    "    create_micropanel,\n",
    ")\n",
    "from lib.preprocess.preprocess import extract_well_metadata, nd2_to_tiff_well\n",
    "from lib.preprocess.file_utils import get_sample_fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Fixed parameters for preprocessing\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing*.\n",
    "- `ROOT_FP`: Path to root of Brieflow output directory*.\n",
    "\n",
    "*Note: Paths can be absolute or relative to where workflows are run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tubhi/secondary-OPS-analysis/brieflow/tests/sbs_test_analysis\n"
     ]
    }
   ],
   "source": [
    "cd /Users/tubhi/secondary-OPS-analysis/brieflow/tests/sbs_test_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\"\n",
    "ROOT_FP = \"/Volumes/SecondaryOPS_TU/brieflow_test_output\"\n",
    "\n",
    "Path(CONFIG_FILE_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(ROOT_FP).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Paths to dataframes with sample information\n",
    "\n",
    "- `SBS_SAMPLES_DF_FP`/`PHENOTYPE_SAMPLES_DF_FP`: Path to dataframe where SBS/phenotype samples location and metadata will be stored.\n",
    "- `SBS_IMAGES_DIR_FP`/`PHENOTYPE_IMAGES_DIR_FP`: Path to directories with SBS/phenotype sample nd2 files. Set to `None` to ignore SBS/phenotype testing in this notebook.\n",
    "\n",
    "### Pattern configurations for metadata extraction\n",
    "\n",
    "#### SBS Configuration\n",
    "- `SBS_PATH_PATTERN`: Regex pattern to match directory structure of SBS files\n",
    "- `SBS_PATH_METADATA`: List of metadata to extract from file path\n",
    "    - Should include at least `\"plate\", \"well\", \"tile, \"cycle\"\"` to extract SBS processing information\n",
    "- `SBS_METADATA_ORDER_TYPE`: Metadata order will be used to organize the file paths dataframe. Metadata types will be used to convert parsed information.\n",
    "\n",
    "#### Phenotype Configuration\n",
    "- `PHENOTYPE_PATH_PATTERN`: Regex pattern to match directory structure of phenotype files  \n",
    "- `PHENOTYPE_PATH_METADATA`: List of metadata to extract from file path\n",
    "    - Should include at least `\"plate\", \"well\", \"tile\"` to extract phentoype processing information\n",
    "- `PHENOTYPE_METADATA_ORDER_TYPE`: Metadata order will be used to organize the file paths dataframe. Metadata types will be used to convert parsed information.\n",
    "\n",
    "*Notes:*\n",
    "- Paths can be absolute or relative to where workflows are run from\n",
    "- Each pattern (path and sample) should have the same number of capture groups as pieces of metadata listed\n",
    "- Metadata lists should be ordered to match the capture groups in their corresponding regex pattern\n",
    "- For both path and sample patterns, numeric values (like cycle numbers) will automatically be converted to integers\n",
    "- For Brieflow to run effectively, each sample fil epath should have an associated plate/well. For single plate/well screens manually add a plate/well to the file path dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to sample dataframes\n",
    "SBS_SAMPLES_DF_FP = '/Users/tubhi/Desktop/Postdoc work/Secondary OPS/Analysis/Genotyping analysis/Brieflow/Pre-process/sbs_samples.tsv'\n",
    "PHENOTYPE_SAMPLES_DF_FP = \"config/phenotype_samples.tsv\"\n",
    "\n",
    "# Directory, pattern, and metadata for SBS sample nd2 files\n",
    "SBS_IMAGES_DIR_FP = '/Volumes/SecondaryOPS_TU/SBS/iBAR1_test'\n",
    "SBS_PATH_PATTERN = r\"plate(\\d+)_.*_c(\\d+)_Well([A-Z]?\\d+)_.*_Seq(\\d+)\\.nd2\"\n",
    "SBS_PATH_METADATA = [\"plate\", \"cycle\", \"well\", \"tile\"]\n",
    "SBS_METADATA_ORDER_TYPE = {\"plate\": int, \"cycle\": int, \"well\": str, \"tile\": int}\n",
    "\n",
    "# Directory, pattern, and metadata for phenotype sample nd2 files\n",
    "PHENOTYPE_IMAGES_DIR_FP = '/Volumes/SecondaryOPS_TU'\n",
    "PHENOTYPE_PATH_PATTERN = r\"plate(\\d+)_Well([A-Z]?\\d+)_.*_Seq(\\d+)\\.nd2\"\n",
    "PHENOTYPE_PATH_METADATA = [\"plate\", \"well\", \"tile\"]\n",
    "PHENOTYPE_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must supply a working regex to the `SBS_PATH_PATTERN` and `PHENOTYPE_PATH_PATTERN` variables. If you don't have experience with regex, you can use the following LLM prompt to generate the patterns.\n",
    "\n",
    "*Enter into a basic LLM chatbot*: \n",
    "\n",
    "Given ND2 filenames from your experiment, generate regex patterns to extract metadata. Return only the regex patterns with no explanation.\n",
    "\n",
    "Example sbs filenames: **[ENTER YOUR EXAMPLE SBS FILES HERE WITH ANY UPSTREAM FOLDER STRUCTURE THAT IS RELEVANT TO THE METADATA]**\n",
    "\n",
    "Example phenotype filenames: **[ENTER YOUR EXAMPLE PHENOTYPE FILES HERE WITH ANY UPSTREAM FOLDER STRUCTURE THAT IS RELEVANT TO THE METADATA]**\n",
    "\n",
    "Required regex patterns (return these exact variable assignments):\n",
    "```python\n",
    "SBS_PATH_PATTERN = r\"...\"      # To match file path structure\n",
    "PHENOTYPE_PATH_PATTERN = r\"...\" # To match file path structure\n",
    "```\n",
    "\n",
    "The patterns should extract:\n",
    "1. SBS pattern:\n",
    "     - Plate number (after \"plate_\")\n",
    "     - Well ID (e.g., \"A1\", \"B2\")\n",
    "     - Tile number (after \"Points-\")\n",
    "     - Cycle number (after \"/c\")\n",
    "2. PHENOTYPE pattern:\n",
    "     - Plate number (after \"plate_\")\n",
    "     - Well ID (e.g., \"A1\", \"B2\")\n",
    "     - Tile number (after \"Points-\")\n",
    "\n",
    "Also provide the corresponding metadata lists and variable types:\n",
    "```python\n",
    "SBS_PATH_METADATA = [\"plate\", \"cycle\", \"well\", \"tile\"]\n",
    "PHENOTYPE_PATH_METADATA = [\"plate\", \"well\", \"tile\"]\n",
    "SBS_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int, \"cycle\": int}\n",
    "PHENOTYPE_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int}\n",
    "```\n",
    "\n",
    "Example patterns for reference:\n",
    "```python\n",
    "SBS_PATH_PATTERN = r\"plate_(\\d+)/c(\\d+)/.*_Wells-([A-Z]\\d+)_Points-(\\d+)__.*\"\n",
    "PHENOTYPE_PATH_PATTERN = r\"P(\\d+)_Pheno_20x_Wells-([A-Z]\\d+)_Points-(\\d+)__.*\"\n",
    "\n",
    "SBS_PATH_METADATA = [\"plate\", \"cycle\", \"well\", \"tile\"]\n",
    "PHENOTYPE_PATH_METADATA = [\"plate\", \"well\", \"tile\"]\n",
    "\n",
    "SBS_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int, \"cycle\": int}\n",
    "PHENOTYPE_METADATA_ORDER_TYPE = {\"plate\": int, \"well\": str, \"tile\": int}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs_samples = create_samples_df(\n",
    "    SBS_IMAGES_DIR_FP, SBS_PATH_PATTERN, SBS_PATH_METADATA, SBS_METADATA_ORDER_TYPE\n",
    ")\n",
    "# Save and display sample dataframe\n",
    "sbs_samples.to_csv(SBS_SAMPLES_DF_FP, sep=\"\\t\", index=False)\n",
    "print(\"SBS samples:\")\n",
    "display(sbs_samples)\n",
    "\n",
    "# Create sample dataframe for phenotype\n",
    "phenotype_samples = create_samples_df(\n",
    "    PHENOTYPE_IMAGES_DIR_FP,\n",
    "    PHENOTYPE_PATH_PATTERN,\n",
    "    PHENOTYPE_PATH_METADATA,\n",
    "    PHENOTYPE_METADATA_ORDER_TYPE,\n",
    ")\n",
    "# Save and display sample dataframe\n",
    "phenotype_samples.to_csv(PHENOTYPE_SAMPLES_DF_FP, sep=\"\\t\", index=False)\n",
    "print(\"Phenotype samples:\")\n",
    "display(phenotype_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Metadata Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SBS_IMAGES_DIR_FP is not None:\n",
    "    # Extract metadata from test sbs sample\n",
    "    test_sbs_metadata = extract_well_metadata(\n",
    "        sbs_samples[\"sample_fp\"][0],\n",
    "        sbs_samples[\"plate\"][0],\n",
    "        sbs_samples[\"well\"][0],\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(\"SBS test metadata:\")\n",
    "    display(test_sbs_metadata)\n",
    "\n",
    "if PHENOTYPE_IMAGES_DIR_FP is not None:\n",
    "    # Extract metadata from test phenotype sample\n",
    "    test_phenotype_metadata = extract_well_metadata(\n",
    "        phenotype_samples[\"sample_fp\"][0],\n",
    "        phenotype_samples[\"plate\"][0],\n",
    "        phenotype_samples[\"well\"][0],\n",
    "        verbose=True,\n",
    "    )\n",
    "    print(\"Phenotype test metadata:\")\n",
    "    display(test_phenotype_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### ND2 conversion\n",
    "\n",
    "- `SBS_CHANNEL_ORDER`/`PHENOTYPE_CHANNEL_ORDER`: Manually set channel order _if ND2 images are acquired as single channels, or there are multiple files for each tile (e.g. multiple rounds of phenotype images). Should be `None` if multichannel image files are acquired. The extracted channel names must match the values that will be displayed in the samples DataFrame channel column (e.g., `[\"DAPI\", \"GFP\", \"CY3\", \"CY5\", \"AF750\"]`).\n",
    "- `PHENOTYPE_ROUND_ORDER`: List of round numbers specifying the order in which to process phenotype image rounds. Should be `None` if there is only one round of phenotyping. For multiple rounds, specify the round numbers in the desired order (e.g., `[1, 2, 3]`). The round numbers must match the values in the samples DataFrame round column.\n",
    "\n",
    "**Note** For single-channel files, each file must contain a channel identifier that your regex can extract. For multichannel files, set the channel patterns to `None`. Metadata extraction is only performed on the first channel dimension for each tile. Please ensure the Dapi channel is displayed first!\n",
    "\n",
    "- `SBS_CHANNEL_ORDER_FLIP`/`PHENOTYPE_CHANNEL_ORDER_FLIP`: Whether or not to flip channel order when converting ND2->tiff. Should be `False` if channels are in a standard order (with Dapi first), or `True` if channels are reversed. This will only occur for multichannel ND2 files, for each individual ND2 file. Setting the channel order for single channel files is done by setting `SBS_CHANNEL_ORDER`/`PHENOTYPE_CHANNEL_ORDER` previously.\n",
    "\n",
    "**Note** Channel order can be checked with the test conversions below. Please ensure the Dapi channel is displayed first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBS_CHANNEL_ORDER = None\n",
    "PHENOTYPE_CHANNEL_ORDER = None\n",
    "PHENOTYPE_ROUND_ORDER = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBS_CHANNEL_ORDER_FLIP = None\n",
    "PHENOTYPE_CHANNEL_ORDER_FLIP = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ND2 Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SBS conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SBS_IMAGES_DIR_FP is not None:\n",
    "    # Get test sbs sample\n",
    "    sbs_sample = get_sample_fps(\n",
    "        sbs_samples,\n",
    "        plate=sbs_samples[\"plate\"][0],\n",
    "        well=sbs_samples[\"well\"][0],\n",
    "        cycle=sbs_samples[\"cycle\"][0],\n",
    "        channel_order=SBS_CHANNEL_ORDER,\n",
    "    )\n",
    "\n",
    "    # Convert test sbs sample to tiff\n",
    "    sbs_image, SBS_TILES = nd2_to_tiff_well(sbs_sample, position=0, channel_order_flip=SBS_CHANNEL_ORDER_FLIP, return_tiles=True, verbose=True)    \n",
    "    # Create micropanel to display converted samples\n",
    "    print(\"Converted SBS test sample:\")\n",
    "    sbs_microimages = [Microimage(image) for image in sbs_image]\n",
    "    sbs_panel = create_micropanel(sbs_microimages, add_channel_label=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test phenotype conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PHENOTYPE_IMAGES_DIR_FP is not None:\n",
    "    # Get test phenotype sample\n",
    "    phenotype_sample = get_sample_fps(\n",
    "        phenotype_samples,\n",
    "        plate=phenotype_samples[\"plate\"][0],\n",
    "        well=phenotype_samples[\"well\"][0],\n",
    "        round_order=PHENOTYPE_ROUND_ORDER,\n",
    "        channel_order=PHENOTYPE_CHANNEL_ORDER,\n",
    "    )\n",
    "    # Convert test phenotype sample to tiff\n",
    "    phenotype_image, PHENOTYPE_TILES = nd2_to_tiff_well(\n",
    "        phenotype_sample, position=0, channel_order_flip=PHENOTYPE_CHANNEL_ORDER_FLIP, return_tiles=True, verbose=True\n",
    "    )\n",
    "\n",
    "    # Create micropanel to display converted samples\n",
    "    print(\"Converted phenotype test sample:\")\n",
    "    phenotype_microimages = [Microimage(image) for image in phenotype_image]\n",
    "    phenotype_panel = create_micropanel(phenotype_microimages, add_channel_label=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Create combo files \n",
    "\n",
    "- `SBS_COMBO_DF_FP`/`PHENOTYPE_COMBO_DF_FP`: Path to dataframe where SBS/phenotype sample metadata combinations will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to combo dataframes\n",
    "SBS_COMBO_DF_FP = \"config/sbs_combo.tsv\"\n",
    "PHENOTYPE_COMBO_DF_FP = \"config/phenotype_combo.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_combos = sbs_samples[SBS_PATH_METADATA].drop_duplicates().astype(str)\n",
    "# Create a list of all tiles\n",
    "tiles = [str(i) for i in range(SBS_TILES)]\n",
    "# Create product of base combos and tiles\n",
    "sbs_wildcard_combos = pd.DataFrame([\n",
    "    {**row.to_dict(), \"tile\": tile}\n",
    "    for _, row in base_combos.iterrows()\n",
    "    for tile in tiles\n",
    "])\n",
    "sbs_wildcard_combos.to_csv(SBS_COMBO_DF_FP, sep=\"\\t\", index=False)\n",
    "print(\"SBS wildcard combos:\")\n",
    "display(sbs_wildcard_combos)\n",
    "\n",
    "base_combos = phenotype_samples[PHENOTYPE_PATH_METADATA].drop_duplicates().astype(str)\n",
    "# Create a list of all tiles\n",
    "tiles = [str(i) for i in range(PHENOTYPE_TILES)]\n",
    "# Create product of base combos and tiles\n",
    "phenotype_wildcard_combos = pd.DataFrame([\n",
    "    {**row.to_dict(), \"tile\": tile}\n",
    "    for _, row in base_combos.iterrows()\n",
    "    for tile in tiles\n",
    "])\n",
    "phenotype_wildcard_combos.to_csv(PHENOTYPE_COMBO_DF_FP, sep=\"\\t\", index=False)\n",
    "print(\"Phenotype wildcard combos:\")\n",
    "display(phenotype_wildcard_combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Calculate illumination correction field\n",
    "\n",
    "- `SAMPLE_FRACTION`: Controls what percentage of images to use when calculating the illumination correction field (0.0-1.0). Using a smaller fraction (e.g., 0.2 = 20%) speeds up processing by randomly sampling only a subset of your images. Default is 1.0 (use all images). For reliable results, ensure your sample contains enough images to accurately represent illumination variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FRACTION = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create config file with params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty config variable\n",
    "config = {}\n",
    "\n",
    "# Add all section\n",
    "config[\"all\"] = {\n",
    "    \"root_fp\": ROOT_FP,\n",
    "}\n",
    "\n",
    "# Add preprocess section\n",
    "config[\"preprocess\"] = {\n",
    "    \"sbs_samples_fp\": SBS_SAMPLES_DF_FP,\n",
    "    \"sbs_combo_fp\": SBS_COMBO_DF_FP,\n",
    "    \"phenotype_samples_fp\": PHENOTYPE_SAMPLES_DF_FP,\n",
    "    \"phenotype_combo_fp\": PHENOTYPE_COMBO_DF_FP,\n",
    "    \"sbs_channel_order\": SBS_CHANNEL_ORDER,\n",
    "    \"phenotype_channel_order\": PHENOTYPE_CHANNEL_ORDER,\n",
    "    \"phenotype_round_order\": PHENOTYPE_ROUND_ORDER,\n",
    "    \"sbs_channel_order_flip\": SBS_CHANNEL_ORDER_FLIP,\n",
    "    \"phenotype_channel_order_flip\": PHENOTYPE_CHANNEL_ORDER_FLIP,\n",
    "    \"sample_fraction\": SAMPLE_FRACTION,\n",
    "}\n",
    "\n",
    "# Write the updated configuration back with markdown-style comments\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    # Write the introductory markdown-style comments\n",
    "    config_file.write(CONFIG_FILE_HEADER)\n",
    "\n",
    "    # Dump the updated YAML structure, keeping markdown comments for sections\n",
    "    yaml.dump(config, config_file, default_flow_style=False, sort_keys=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
